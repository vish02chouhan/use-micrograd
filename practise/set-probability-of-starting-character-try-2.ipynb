{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #Consider .=0, a = 1, b = 2, c = 3, d = 4\n",
    "Example - cab\n",
    " .cab.\n",
    "\n",
    " xs_c = [\".\",\"c\",\"a\",\"b\"]\n",
    " ys_c = [\"c\",\"a\",\"b\",\".\"]\n",
    " #we can also visualize it as\n",
    " ##[\".c\",\"ca\",\"ab\",\"b.\"]\n",
    "\n",
    " xs = [0,3,1,2]\n",
    " ys = [3,1,2,0]\n",
    "\n",
    " encode cab with 5 class\n",
    "\n",
    "                .[1,0,0,0,0]\n",
    "                c[0,0,0,1,0]\n",
    " xenc     =     a[0,1,0,0,0]     \n",
    "                b[0,0,1,0,0]\n",
    "\n",
    "\n",
    "     \n",
    "                 [\n",
    "                  [ 1.5674, -0.2373, -0.0274, -1.1008,  0.2859],\n",
    "                  [-0.0296, -1.5471,  0.6049,  0.0791, -0.7814],\n",
    "                  [-0.2808, -0.7389,  1.7249,  0.0380, -1.0694],\n",
    "                  [-0.5374,  0.0511, -0.4755,  0.6205,  1.1500],\n",
    "                  [-0.9643, -0.8815, -0.8295, -0.2548, -0.9648]\n",
    "                 ]\n",
    "\n",
    "logits_for_dot = [-0.2808, -0.7389,  1.7249,  0.0380, -1.0694] #3rd row -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 1, 2]) tensor([3, 1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "token = \".abcd\"\n",
    "stoi ={ char:index for index,char in enumerate(token)}\n",
    "itos ={char:index  for index,char in stoi.items()}\n",
    "\n",
    "\n",
    "data = \"cab\"\n",
    "data_ind = \".cab.\"\n",
    "xs,ys = [],[]\n",
    "\n",
    "for x,y in zip(data_ind,data_ind[1:]):\n",
    "    xs.append(stoi[x])\n",
    "    ys.append(stoi[y])\n",
    "\n",
    "xs =  torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=5).float() # input to the network: one-hot encoding\n",
    "print(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2963,  1.1951,  0.7433, -0.1034, -0.6192],\n",
      "        [ 2.6439,  1.7843,  0.2086,  0.5000,  0.4406],\n",
      "        [-0.6386,  0.2266, -0.0906, -0.3895, -0.2717],\n",
      "        [-0.2562, -0.7472, -0.8306, -1.2820,  0.2468],\n",
      "        [-1.3791, -1.8291, -0.4827,  0.2922,  0.4291]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "W = torch.tensor([\n",
    "\n",
    "[ 0.2963, 1.1951, 0.7433, -0.1034, -0.6192],\n",
    "\n",
    "[ 2.6439, 1.7843, 0.2086, 0.5000, 0.4406], \n",
    "\n",
    "[-0.6386, 0.2266, -0.0906, -0.3895, -0.2717],\n",
    "\n",
    "[-0.2562, -0.7472, -0.8306, -1.2820, 0.2468],\n",
    "\n",
    "[-1.3791, -1.8291, -0.4827, 0.2922, 0.4291]\n",
    "\n",
    "], requires_grad=True)\n",
    "\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2963,  1.1951,  0.7433, -0.1034, -0.6192],\n",
      "        [-0.2562, -0.7472, -0.8306, -1.2820,  0.2468],\n",
      "        [ 2.6439,  1.7843,  0.2086,  0.5000,  0.4406],\n",
      "        [-0.6386,  0.2266, -0.0906, -0.3895, -0.2717]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#W = torch.randn((5, 5), requires_grad=True)\n",
    "#print(W)\n",
    "logits = xenc @ W\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.34  3.3   2.1   0.9   0.54]\n",
      " [ 0.77  0.47  0.44  0.28  1.28]\n",
      " [14.07  5.96  1.23  1.65  1.55]\n",
      " [ 0.53  1.25  0.91  0.68  0.76]]\n",
      "[[0.16 0.4  0.26 0.11 0.07]\n",
      " [0.24 0.15 0.13 0.09 0.39]\n",
      " [0.58 0.24 0.05 0.07 0.06]\n",
      " [0.13 0.3  0.22 0.16 0.18]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "\n",
    "array = np.array(counts.data.tolist())\n",
    "print(np.around(array, decimals=2))\n",
    "\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "array = np.array(probs.data.tolist())\n",
    "print(np.around(array, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-probs[torch.arange(len(xs)), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3392, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.05*(W**2).mean()\n",
    "print(loss)\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_format(d):\n",
    "    array = np.array(d.data.tolist())\n",
    "    print(np.around(array, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.042  0.106  0.067 -0.223  0.014]\n",
      " [ 0.154  0.068 -0.237  0.019  0.018]\n",
      " [-0.221  0.077  0.055  0.039  0.045]\n",
      " [ 0.059 -0.216  0.03   0.016  0.1  ]\n",
      " [-0.006 -0.007 -0.002  0.001  0.002]]\n"
     ]
    }
   ],
   "source": [
    "cust_format(W.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.815 -4.085 -2.614 11.041 -1.317]\n",
      " [-5.075 -1.616 12.037 -0.443 -0.442]\n",
      " [10.393 -3.61  -2.833 -2.359 -2.521]\n",
      " [-3.19  10.075 -2.345 -2.096 -4.739]\n",
      " [-1.103 -1.463 -0.386  0.234  0.343]]\n"
     ]
    }
   ],
   "source": [
    "W.data += -50 * W.grad\n",
    "cust_format(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2963, 1.1951, 0.7433, 0.1034, 0.6192]\n",
      "2.9573\n",
      "[0.10019274338078653, 0.40411862171575424, 0.25134413147127443, 0.03496432556724039, 0.20938017786494437]\n"
     ]
    }
   ],
   "source": [
    "aa = [ 0.2963, 1.1951, 0.7433, -0.1034, -0.6192]\n",
    "aa = [ abs(num) for num in aa]\n",
    "print(aa)\n",
    "total = sum(aa)\n",
    "print(total)\n",
    "prob = [num/total for num in aa]\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "ca\n",
      "cab\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "ix = 0\n",
    "while True:\n",
    " \n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=5).float()\n",
    "    logits = xenc @ W\n",
    "        \n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "        # ----------\n",
    "        \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "    out.append(itos[ix])\n",
    "    if len(out) > 5:\n",
    "        break\n",
    "    if ix == 0:\n",
    "        break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
