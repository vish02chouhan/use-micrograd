{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #Consider .=0, a = 1, b = 2, c = 3, d = 4\n",
    "Example - cab\n",
    " .cab.\n",
    "\n",
    " xs_c = [\".\",\"c\",\"a\",\"b\"]\n",
    " ys_c = [\"c\",\"a\",\"b\",\".\"]\n",
    " #we can also visualize it as\n",
    " ##[\".c\",\"ca\",\"ab\",\"b.\"]\n",
    "\n",
    " xs = [0,3,1,2]\n",
    " ys = [3,1,2,0]\n",
    "\n",
    " encode cab with 5 class\n",
    "\n",
    "                .[1,0,0,0,0]\n",
    "                c[0,0,0,1,0]\n",
    " xenc     =     a[0,1,0,0,0]     \n",
    "                b[0,0,1,0,0]\n",
    "\n",
    "\n",
    "     \n",
    "                 [\n",
    "                  [ 1.5674, -0.2373, -0.0274, -1.1008,  0.2859],\n",
    "                  [-0.0296, -1.5471,  0.6049,  0.0791, -0.7814],\n",
    "                  [-0.2808, -0.7389,  1.7249,  0.0380, -1.0694],\n",
    "                  [-0.5374,  0.0511, -0.4755,  0.6205,  1.1500],\n",
    "                  [-0.9643, -0.8815, -0.8295, -0.2548, -0.9648]\n",
    "                 ]\n",
    "\n",
    "logits_for_dot = [-0.2808, -0.7389,  1.7249,  0.0380, -1.0694] #3rd row -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "token = \".abcd\"\n",
    "stoi ={ char:index for index,char in enumerate(token)}\n",
    "itos ={char:index  for index,char in stoi.items()}\n",
    "\n",
    "\n",
    "data = \"cab\"\n",
    "data_ind = \".cab.\"\n",
    "xs,ys = [],[]\n",
    "\n",
    "for x,y in zip(data_ind,data_ind[1:]):\n",
    "    xs.append(stoi[x])\n",
    "    ys.append(stoi[y])\n",
    "\n",
    "xs =  torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=5).float() # input to the network: one-hot encoding\n",
    "print(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((5, 5), requires_grad=True)\n",
    "print(W)\n",
    "logits = xenc @ W\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "\n",
    "array = np.array(counts.data.tolist())\n",
    "print(np.around(array, decimals=2))\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "array = np.array(probs.data.tolist())\n",
    "print(np.around(array, decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-probs[torch.arange(len(xs)), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.05*(W**2).mean()\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_format(d):\n",
    "    array = np.array(d.data.tolist())\n",
    "    print(np.around(array, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_format(W.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -50 * W.grad\n",
    "cust_format(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [ 0.2963, 1.1951, 0.7433, -0.1034, -0.6192]\n",
    "aa = [ abs(num) for num in aa]\n",
    "print(aa)\n",
    "total = sum(aa)\n",
    "print(total)\n",
    "prob = [num/total for num in aa]\n",
    "print(prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
