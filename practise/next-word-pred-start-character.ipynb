{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data = \".abcd\"\n",
    "\n",
    "stoi = { char:i for i,char in enumerate(data)}\n",
    "itos = { i:char for i,char in enumerate(data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "example = \"c\"\n",
    "#. -> c\n",
    "xenc = F.one_hot(torch.tensor([0]), num_classes=5).float()\n",
    "print(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W = torch.tensor(\n",
    "    [\n",
    "\n",
    "[ 0.2963, 1.1951, 0.7433, -0.1034, -0.6192],\n",
    "\n",
    "[ 2.6439, 1.7843, 0.2086, 0.5000, 0.4406], \n",
    "\n",
    "[-0.6386, 0.2266, -0.0906, -0.3895, -0.2717],\n",
    "\n",
    "[-0.2562, -0.7472, -0.8306, -1.2820, 0.2468],\n",
    "\n",
    "[-1.3791, -1.8291, -0.4827, 0.2922, 0.4291]\n",
    "\n",
    "]\n",
    "    , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2963,  1.1951,  0.7433, -0.1034, -0.6192]], grad_fn=<MmBackward0>)\n",
      "tensor([[0.1642, 0.4033, 0.2567, 0.1101, 0.0657]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "print(logits)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True) \n",
    "print(probs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2065, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = -probs[torch.arange(1), [3]].log().mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1642,  0.4033,  0.2567, -0.8899,  0.0657],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(W.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.9124, -18.9708, -12.0919,  44.3925,  -3.9053],\n",
      "        [  2.6439,   1.7843,   0.2086,   0.5000,   0.4406],\n",
      "        [ -0.6386,   0.2266,  -0.0906,  -0.3895,  -0.2717],\n",
      "        [ -0.2562,  -0.7472,  -0.8306,  -1.2820,   0.2468],\n",
      "        [ -1.3791,  -1.8291,  -0.4827,   0.2922,   0.4291]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W.data += -50 * W.grad\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.]])\n",
      "tensor([[ -7.9124, -18.9708, -12.0919,  44.3925,  -3.9053]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[1.9243e-23, 3.0316e-28, 2.9453e-25, 1.0000e+00, 1.0581e-21]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(torch.tensor([0]), num_classes=5).float()\n",
    "print(xenc)\n",
    "logits = xenc @ W\n",
    "print(logits)\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True) \n",
    "print(probs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
