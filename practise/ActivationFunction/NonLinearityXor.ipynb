{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple Neural Network with one hidden layer (2 neurons) and non-linear activation functions\n",
    "class SimpleXORNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleXORNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()       # Non-linear activation function\n",
    "        self.fc2 = nn.Linear(2, 1)  # Hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "net = SimpleXORNet()\n",
    "\n",
    "# XOR inputs and outputs\n",
    "inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "outputs = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.16700142621994019\n",
      "Epoch 200, Loss: 0.1666666716337204\n",
      "Epoch 300, Loss: 0.1666666716337204\n",
      "Epoch 400, Loss: 0.1666666716337204\n",
      "Epoch 500, Loss: 0.1666666716337204\n",
      "Epoch 600, Loss: 0.1666666716337204\n",
      "Epoch 700, Loss: 0.1666666716337204\n",
      "Epoch 800, Loss: 0.1666666716337204\n",
      "Epoch 900, Loss: 0.1666666716337204\n",
      "Epoch 1000, Loss: 0.1666666716337204\n",
      "Epoch 1100, Loss: 0.1666666716337204\n",
      "Epoch 1200, Loss: 0.1666666716337204\n",
      "Epoch 1300, Loss: 0.1666666716337204\n",
      "Epoch 1400, Loss: 0.1666666716337204\n",
      "Epoch 1500, Loss: 0.1666666716337204\n",
      "Epoch 1600, Loss: 0.1666666716337204\n",
      "Epoch 1700, Loss: 0.1666666716337204\n",
      "Epoch 1800, Loss: 0.1666666716337204\n",
      "Epoch 1900, Loss: 0.1666666716337204\n",
      "Epoch 2000, Loss: 0.1666666716337204\n",
      "Epoch 2100, Loss: 0.1666666716337204\n",
      "Epoch 2200, Loss: 0.1666666716337204\n",
      "Epoch 2300, Loss: 0.1666666716337204\n",
      "Epoch 2400, Loss: 0.1666666716337204\n",
      "Epoch 2500, Loss: 0.1666666716337204\n",
      "Epoch 2600, Loss: 0.1666666716337204\n",
      "Epoch 2700, Loss: 0.1666666716337204\n",
      "Epoch 2800, Loss: 0.1666666716337204\n",
      "Epoch 2900, Loss: 0.1666666716337204\n",
      "Epoch 3000, Loss: 0.1666666716337204\n",
      "Epoch 3100, Loss: 0.1666666716337204\n",
      "Epoch 3200, Loss: 0.1666666716337204\n",
      "Epoch 3300, Loss: 0.1666666716337204\n",
      "Epoch 3400, Loss: 0.1666666716337204\n",
      "Epoch 3500, Loss: 0.1666666716337204\n",
      "Epoch 3600, Loss: 0.1666666716337204\n",
      "Epoch 3700, Loss: 0.1666666716337204\n",
      "Epoch 3800, Loss: 0.1666666716337204\n",
      "Epoch 3900, Loss: 0.1666666716337204\n",
      "Epoch 4000, Loss: 0.1666666716337204\n",
      "Epoch 4100, Loss: 0.1666666716337204\n",
      "Epoch 4200, Loss: 0.1666666716337204\n",
      "Epoch 4300, Loss: 0.1666666716337204\n",
      "Epoch 4400, Loss: 0.1666666716337204\n",
      "Epoch 4500, Loss: 0.1666666716337204\n",
      "Epoch 4600, Loss: 0.1666666716337204\n",
      "Epoch 4700, Loss: 0.1666666716337204\n",
      "Epoch 4800, Loss: 0.1666666716337204\n",
      "Epoch 4900, Loss: 0.1666666716337204\n",
      "Epoch 5000, Loss: 0.1666666716337204\n",
      "Epoch 5100, Loss: 0.1666666716337204\n",
      "Epoch 5200, Loss: 0.1666666716337204\n",
      "Epoch 5300, Loss: 0.1666666716337204\n",
      "Epoch 5400, Loss: 0.1666666716337204\n",
      "Epoch 5500, Loss: 0.1666666716337204\n",
      "Epoch 5600, Loss: 0.1666666716337204\n",
      "Epoch 5700, Loss: 0.1666666716337204\n",
      "Epoch 5800, Loss: 0.1666666716337204\n",
      "Epoch 5900, Loss: 0.1666666716337204\n",
      "Epoch 6000, Loss: 0.1666666716337204\n",
      "Epoch 6100, Loss: 0.1666666716337204\n",
      "Epoch 6200, Loss: 0.1666666716337204\n",
      "Epoch 6300, Loss: 0.1666666716337204\n",
      "Epoch 6400, Loss: 0.1666666716337204\n",
      "Epoch 6500, Loss: 0.1666666716337204\n",
      "Epoch 6600, Loss: 0.1666666716337204\n",
      "Epoch 6700, Loss: 0.1666666716337204\n",
      "Epoch 6800, Loss: 0.1666666716337204\n",
      "Epoch 6900, Loss: 0.1666666716337204\n",
      "Epoch 7000, Loss: 0.1666666716337204\n",
      "Epoch 7100, Loss: 0.1666666716337204\n",
      "Epoch 7200, Loss: 0.1666666716337204\n",
      "Epoch 7300, Loss: 0.1666666716337204\n",
      "Epoch 7400, Loss: 0.1666666716337204\n",
      "Epoch 7500, Loss: 0.1666666716337204\n",
      "Epoch 7600, Loss: 0.1666666716337204\n",
      "Epoch 7700, Loss: 0.1666666716337204\n",
      "Epoch 7800, Loss: 0.1666666716337204\n",
      "Epoch 7900, Loss: 0.1666666716337204\n",
      "Epoch 8000, Loss: 0.1666666716337204\n",
      "Epoch 8100, Loss: 0.1666666716337204\n",
      "Epoch 8200, Loss: 0.1666666716337204\n",
      "Epoch 8300, Loss: 0.1666666716337204\n",
      "Epoch 8400, Loss: 0.1666666716337204\n",
      "Epoch 8500, Loss: 0.1666666716337204\n",
      "Epoch 8600, Loss: 0.1666666716337204\n",
      "Epoch 8700, Loss: 0.1666666716337204\n",
      "Epoch 8800, Loss: 0.1666666716337204\n",
      "Epoch 8900, Loss: 0.1666666716337204\n",
      "Epoch 9000, Loss: 0.1666666716337204\n",
      "Epoch 9100, Loss: 0.1666666716337204\n",
      "Epoch 9200, Loss: 0.1666666716337204\n",
      "Epoch 9300, Loss: 0.1666666716337204\n",
      "Epoch 9400, Loss: 0.1666666716337204\n",
      "Epoch 9500, Loss: 0.1666666716337204\n",
      "Epoch 9600, Loss: 0.1666666716337204\n",
      "Epoch 9700, Loss: 0.1666666716337204\n",
      "Epoch 9800, Loss: 0.1666666716337204\n",
      "Epoch 9900, Loss: 0.1666666716337204\n",
      "Epoch 10000, Loss: 0.1666666716337204\n",
      "Input: tensor([0., 0.]), Predicted: 0.33333340287208557, Actual: 0.0\n",
      "Input: tensor([0., 1.]), Predicted: 0.33333340287208557, Actual: 1.0\n",
      "Input: tensor([1., 0.]), Predicted: 1.0, Actual: 1.0\n",
      "Input: tensor([1., 1.]), Predicted: 0.33333340287208557, Actual: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    predicted = net(inputs)\n",
    "    loss = criterion(predicted, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    for input, label in zip(inputs, outputs):\n",
    "        predicted = net(input)\n",
    "        print(f'Input: {input}, Predicted: {predicted.item()}, Actual: {label.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 0.2515594959259033\n",
      "Epoch 200, Loss: 0.25035959482192993\n",
      "Epoch 300, Loss: 0.2500947117805481\n",
      "Epoch 400, Loss: 0.25002816319465637\n",
      "Epoch 500, Loss: 0.2500094175338745\n",
      "Epoch 600, Loss: 0.2500034272670746\n",
      "Epoch 700, Loss: 0.25000131130218506\n",
      "Epoch 800, Loss: 0.250000536441803\n",
      "Epoch 900, Loss: 0.2500002086162567\n",
      "Epoch 1000, Loss: 0.25000008940696716\n",
      "Input: tensor([0., 0.]), Predicted: 0.4999260902404785, Actual: 0.0\n",
      "Input: tensor([0., 1.]), Predicted: 0.5004004240036011, Actual: 1.0\n",
      "Input: tensor([1., 0.]), Predicted: 0.49959295988082886, Actual: 1.0\n",
      "Input: tensor([1., 1.]), Predicted: 0.5000672340393066, Actual: 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple linear Neural Network (no non-linear activation functions)\n",
    "class SimpleLinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)  # Input layer to hidden layer (linear)\n",
    "        self.fc2 = nn.Linear(2, 1)  # Hidden layer to output layer (linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "linear_net = SimpleLinearNet()\n",
    "\n",
    "# XOR inputs and outputs\n",
    "inputs = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "outputs = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(linear_net.parameters(), lr=0.1)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    predicted = linear_net(inputs)\n",
    "    loss = criterion(predicted, outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 99:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Test the network\n",
    "with torch.no_grad():\n",
    "    for input, label in zip(inputs, outputs):\n",
    "        predicted = linear_net(input)\n",
    "        print(f'Input: {input}, Predicted: {predicted.item()}, Actual: {label.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
